# -*- coding: utf-8 -*-
"""ocr-pan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OnDVSxV-hoIWhF_qLVsop70pIejNweub
"""

!pip install ftfy

!pip install pytesseract

# for ocr  

!sudo apt install tesseract-ocr

import os
import ftfy
import pytesseract
import re
import math
from scipy import ndimage
import cv2
import numpy as np

# reading file from path
def pan(image_path):
    
    img = cv2.imread(image_path)
    img_before = cv2.imread(image_path)
    img_gray = cv2.cvtColor(img_before, cv2.COLOR_BGR2GRAY)# converting image to gray scale to remove noise and colour complexity
    img_edges = cv2.Canny(img_gray, 100, 100, apertureSize=3)# canny edge detector detects edges in an image
    
#Calculating rotation angle of the image
    lines = cv2.HoughLinesP(img_edges, 1, math.pi / 180.0, 100, minLineLength=100, maxLineGap=5 )#detects any shape but here horizontal lines if any

    # Caclulating angle of lines detected 
    angles = []

    for [[x1, y1, x2, y2]] in lines:
        cv2.line(img_before, (x1, y1), (x2, y2), (255, 0, 0), 3)
        angle = math.degrees(math.atan2(y2 - y1, x2 - x1))
        angles.append(angle)
    median_angle = np.median(angles)
    print("image rotated by",median_angle,"angle")
    
    

# If-else block to check and rotate image and applying  pytesseract on final rotated images
    if median_angle!=0:
        img_rotated = ndimage.rotate(img, (median_angle*2-1))
    # extracting text from image using tesseract
        text = pytesseract.image_to_string(img_rotated)
    else:
        text = pytesseract.image_to_string(img_gray)

    text = ftfy.fix_text(text)

    
    
# Applying regex to obtain date(dob) and Pan number
    dob=re.search(r'\d{2}/\d{2}/\d{4}', text)    # regex for date of birth
    pan_no=re.search('[A-Z]{5}[0-9]{4}[A-Z]{1}',text)  #regex for pan_number
    print("pan card number:",pan_no.group()) 
    print("dob on pan card:",dob.group())
    # bounding_box(img)

def bounding_box(img):

    cord = output[index][0]
    cord1 = output[index1][0]

    x_min, y_min = [int(min(idx)) for idx in zip(*cord)]
    x_max, y_max = [int(max(idx)) for idx in zip(*cord)]
    x1_min, y1_min = [int(min(idx)) for idx in zip(*cord1)]
    x1_max, y1_max = [int(max(idx)) for idx in zip(*cord1)]

    # image = cv2.imread(img)
    cv2.rectangle(img,(x_min,y_min),(x_max,y_max),(0,0,255),2)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

    cv2.rectangle(image,(x1_min,y1_min),(x1_max,y1_max),(0,0,255),2)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

pan('/content/sample_data/card1.jpg')
pan('/content/sample_data/card2.jpg')

pan('/content/sample_data/card3.jpg')

ocr_on_pan('/content/sample_data/card2.jpg')